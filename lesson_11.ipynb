{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN86B4G+l1V5dPT8z3lgkp0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FKz11/NLP/blob/main/lesson_11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lesson-11"
      ],
      "metadata": {
        "id": "7J5Rm2oW58yi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Задание\n",
        "1. Взять предобученную трансформерную архитектуру и решить задачу перевода (для тогоже корпуса что вы выбрали из предыдущего дз)\n",
        "2. скачиваем готовый новостной датасет\n",
        "скачиваем из\n",
        "https://github.com/natasha/corus/blob/master/README.md\n",
        "любой новостной датасет\n",
        "\n",
        "    реализовать метод поиска ближайших статей\n",
        "    (на вход метода должен приходить запрос (какой-то вопрос) и количество вариантов вывода к примеру топ 5-ть или 3-ри, ваш метод должен возвращать топ-k ближайших статей к этому запросу)\n",
        "    визуально оценить качество"
      ],
      "metadata": {
        "id": "Dq0C1M9Y6o9r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Библиотеки:"
      ],
      "metadata": {
        "id": "zO0TeNaE6Wsc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DcIY4kEZ543D"
      },
      "outputs": [],
      "source": [
        "!pip install -qq transformers[sentencepiece]\n",
        "\n",
        "import transformers\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import AutoModelForSeq2SeqLM"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Взять предобученную трансформерную архитектуру и решить задачу перевода (для тогоже корпуса что вы выбрали из предыдущего дз)"
      ],
      "metadata": {
        "id": "xMR6SGMx6taZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Данные:"
      ],
      "metadata": {
        "id": "kaLypFQx6ZLN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test = [('Yesterday we were in the park.', 'Вчера мы были в парке.'),\n",
        "('Our team won.', 'Наша команда выиграла.'),\n",
        "('I bought а new computer.', 'Я купил новый компьютер.'),\n",
        "('Yesterday we played football.', 'Вчера мы играли в футбол.'),\n",
        "('Nobody saw animals.', 'Никто не видел животных.'),\n",
        "('The children sang songs.', 'Дети пели песню.'),\n",
        "('The angry dog bit a small girl in the street.', 'Злая собака укусила девочку на улице.'),\n",
        "('Who went to the cinema  yesterday?', 'Кто ходил вчера в кино?'),\n",
        "(\"He came to school at 8 o'clock.\", 'Он пришёл в школу в 8 часов.'),\n",
        "('Spring is the season succeeding Winter and preceding Summer.', 'Весна - это сезон, следующий за Зимой и перед летом.'),\n",
        "('I have to go to the university now but I will come back soon.', 'Я должен пойти сейчас в университет, но я скоро вернусь.'),\n",
        "(\"Yesterday at school somebody stole the money from my friend's bag.\", 'Вчера в школе кто-то украл деньги из сумки моей подруги.')]"
      ],
      "metadata": {
        "id": "M3bitv9l8EcO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_x = list(map(lambda x: x[1], test))\n",
        "text_x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNXVPpp-KWrT",
        "outputId": "cc1bf41d-c377-4a8b-a2f8-54e8bd0d0f27"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Вчера мы были в парке.',\n",
              " 'Наша команда выиграла.',\n",
              " 'Я купил новый компьютер.',\n",
              " 'Вчера мы играли в футбол.',\n",
              " 'Никто не видел животных.',\n",
              " 'Дети пели песню.',\n",
              " 'Злая собака укусила девочку на улице.',\n",
              " 'Кто ходил вчера в кино?',\n",
              " 'Он пришёл в школу в 8 часов.',\n",
              " 'Весна - это сезон, следующий за Зимой и перед летом.',\n",
              " 'Я должен пойти сейчас в университет, но я скоро вернусь.',\n",
              " 'Вчера в школе кто-то украл деньги из сумки моей подруги.']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_y = list(map(lambda x: x[0], test))\n",
        "text_y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBVhySrrKsWF",
        "outputId": "54509e34-b263-4356-a4cc-13d97f48421b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Yesterday we were in the park.',\n",
              " 'Our team won.',\n",
              " 'I bought а new computer.',\n",
              " 'Yesterday we played football.',\n",
              " 'Nobody saw animals.',\n",
              " 'The children sang songs.',\n",
              " 'The angry dog bit a small girl in the street.',\n",
              " 'Who went to the cinema  yesterday?',\n",
              " \"He came to school at 8 o'clock.\",\n",
              " 'Spring is the season succeeding Winter and preceding Summer.',\n",
              " 'I have to go to the university now but I will come back soon.',\n",
              " \"Yesterday at school somebody stole the money from my friend's bag.\"]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Модель:"
      ],
      "metadata": {
        "id": "SstqXoYl8k4D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-ru-en\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BVV1omym9OHW",
        "outputId": "5b8eada4-3967-4fb4-a712-d7b2a31bd532"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/models/marian/tokenization_marian.py:194: UserWarning: Recommended: pip install sacremoses.\n",
            "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"Helsinki-NLP/opus-mt-ru-en\")"
      ],
      "metadata": {
        "id": "ownaN9xI-nbE"
      },
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predict"
      ],
      "metadata": {
        "id": "SqmV6aGUKOo2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(text_x, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "outputs = model.generate(inputs['input_ids'], max_length=200)\n",
        "outputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cbx5UH_kKSg1",
        "outputId": "f65a5839-1888-4896-c89d-ea56190c4ea1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[62517,   156,   102,    10,     4, 14807,  9752,     3,     0, 62517,\n",
              "         62517, 62517, 62517, 62517, 62517, 62517, 62517, 62517],\n",
              "        [62517,  2822,  2643,  2169,     3,     0, 62517, 62517, 62517, 62517,\n",
              "         62517, 62517, 62517, 62517, 62517, 62517, 62517, 62517],\n",
              "        [62517,    29, 11704,    13,   297,  7201,     3,     0, 62517, 62517,\n",
              "         62517, 62517, 62517, 62517, 62517, 62517, 62517, 62517],\n",
              "        [62517,   156,  5734, 22095,  9752,     3,     0, 62517, 62517, 62517,\n",
              "         62517, 62517, 62517, 62517, 62517, 62517, 62517, 62517],\n",
              "        [62517,   170,   159,    18,    23,  2133,   254, 17848,     3,     0,\n",
              "         62517, 62517, 62517, 62517, 62517, 62517, 62517, 62517],\n",
              "        [62517,    32,   365, 44337,    13, 10924,     3,     0, 62517, 62517,\n",
              "         62517, 62517, 62517, 62517, 62517, 62517, 62517, 62517],\n",
              "        [62517,  1603, 15615,  8870,  2681,    13,  2616,    25,     4,  9310,\n",
              "             3,     0, 62517, 62517, 62517, 62517, 62517, 62517],\n",
              "        [62517,  1437,  2500,     9,     4, 25583,  9752,    19,     0, 62517,\n",
              "         62517, 62517, 62517, 62517, 62517, 62517, 62517, 62517],\n",
              "        [62517,   160,  1855,     9,  1599,    59,   331,  6844,     3,     0,\n",
              "         62517, 62517, 62517, 62517, 62517, 62517, 62517, 62517],\n",
              "        [62517, 34858,    34,     4, 14347,   582, 20357,     8,   483, 11361,\n",
              "             3,     0, 62517, 62517, 62517, 62517, 62517, 62517],\n",
              "        [62517,    29,    63,     9,   248,     9, 12106,   404,     2,   181,\n",
              "            29,    18,   356,    36,   207,   559,     3,     0],\n",
              "        [62517, 35373,    59,  1599,     2,  2510, 18340,  1693,    65,   163,\n",
              "          3250,    18,    23, 11287,     3,     0, 62517, 62517]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Тест"
      ],
      "metadata": {
        "id": "01b6e37dKJ1Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(test)):\n",
        "  print('Input: {}'.format(text_x[i]))\n",
        "  print('Predicted translation: {}'.format(tokenizer.decode(outputs[i], skip_special_tokens=True)))\n",
        "  print('True translation: {}'.format(text_y[i]))\n",
        "  print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5inAUzaFGAWa",
        "outputId": "ba8511d3-ca4d-47ba-9c43-7c50cda6db86"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: Вчера мы были в парке.\n",
            "Predicted translation: We were in the park yesterday.\n",
            "True translation: Yesterday we were in the park.\n",
            "\n",
            "Input: Наша команда выиграла.\n",
            "Predicted translation: Our team won.\n",
            "True translation: Our team won.\n",
            "\n",
            "Input: Я купил новый компьютер.\n",
            "Predicted translation: I bought a new computer.\n",
            "True translation: I bought а new computer.\n",
            "\n",
            "Input: Вчера мы играли в футбол.\n",
            "Predicted translation: We played football yesterday.\n",
            "True translation: Yesterday we played football.\n",
            "\n",
            "Input: Никто не видел животных.\n",
            "Predicted translation: No one's seen any animals.\n",
            "True translation: Nobody saw animals.\n",
            "\n",
            "Input: Дети пели песню.\n",
            "Predicted translation: The children sang a song.\n",
            "True translation: The children sang songs.\n",
            "\n",
            "Input: Злая собака укусила девочку на улице.\n",
            "Predicted translation: An angry dog bit a girl on the street.\n",
            "True translation: The angry dog bit a small girl in the street.\n",
            "\n",
            "Input: Кто ходил вчера в кино?\n",
            "Predicted translation: Who went to the movies yesterday?\n",
            "True translation: Who went to the cinema  yesterday?\n",
            "\n",
            "Input: Он пришёл в школу в 8 часов.\n",
            "Predicted translation: He came to school at 8:00.\n",
            "True translation: He came to school at 8 o'clock.\n",
            "\n",
            "Input: Весна - это сезон, следующий за Зимой и перед летом.\n",
            "Predicted translation: Spring is the season after winter and before summer.\n",
            "True translation: Spring is the season succeeding Winter and preceding Summer.\n",
            "\n",
            "Input: Я должен пойти сейчас в университет, но я скоро вернусь.\n",
            "Predicted translation: I have to go to university now, but I'll be right back.\n",
            "True translation: I have to go to the university now but I will come back soon.\n",
            "\n",
            "Input: Вчера в школе кто-то украл деньги из сумки моей подруги.\n",
            "Predicted translation: Yesterday at school, someone stole money from my friend's bag.\n",
            "True translation: Yesterday at school somebody stole the money from my friend's bag.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Вывод:\n",
        "\n",
        "Перевод просто отличный, местами даже лучше, чем настоящий. Где-то конечно есть лишняя запятая или не тот предлог. Но в целом суть более чем понятна. Во много раз лучше, чем модель на рекуретных сетях со слоем внимания."
      ],
      "metadata": {
        "id": "ZvTJQj1_OP2m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. скачиваем готовый новостной датасет скачиваем из https://github.com/natasha/corus/blob/master/README.md любой новостной датасет\n",
        "\n",
        "реализовать метод поиска ближайших статей (на вход метода должен приходить запрос (какой-то вопрос) и количество вариантов вывода к примеру топ 5-ть или 3-ри, ваш метод должен возвращать топ-k ближайших статей к этому запросу) визуально оценить качество"
      ],
      "metadata": {
        "id": "U0hUPz0KPB9u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Данные"
      ],
      "metadata": {
        "id": "bALZSnmtPZM7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qq corus"
      ],
      "metadata": {
        "id": "S8EVSz4CPgdV"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/yutkin/Lenta.Ru-News-Dataset/releases/download/v1.0/lenta-ru-news.csv.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HAdeo2BaQSsi",
        "outputId": "71283e68-77a4-4c9e-8ce8-72f57ee249f0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-09-25 22:13:06--  https://github.com/yutkin/Lenta.Ru-News-Dataset/releases/download/v1.0/lenta-ru-news.csv.gz\n",
            "Resolving github.com (github.com)... 20.205.243.166\n",
            "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/87156914/0b363e00-0126-11e9-9e3c-e8c235463bd6?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220925%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220925T221306Z&X-Amz-Expires=300&X-Amz-Signature=bc2e15144d4c00bfb8b4905059066c276714d003b4e6905ea235dbed03934e23&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=87156914&response-content-disposition=attachment%3B%20filename%3Dlenta-ru-news.csv.gz&response-content-type=application%2Foctet-stream [following]\n",
            "--2022-09-25 22:13:06--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/87156914/0b363e00-0126-11e9-9e3c-e8c235463bd6?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220925%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220925T221306Z&X-Amz-Expires=300&X-Amz-Signature=bc2e15144d4c00bfb8b4905059066c276714d003b4e6905ea235dbed03934e23&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=87156914&response-content-disposition=attachment%3B%20filename%3Dlenta-ru-news.csv.gz&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 527373240 (503M) [application/octet-stream]\n",
            "Saving to: ‘lenta-ru-news.csv.gz.6’\n",
            "\n",
            "lenta-ru-news.csv.g 100%[===================>] 502.94M   322MB/s    in 1.6s    \n",
            "\n",
            "2022-09-25 22:13:08 (322 MB/s) - ‘lenta-ru-news.csv.gz.6’ saved [527373240/527373240]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from corus import load_lenta\n",
        "\n",
        "path = 'lenta-ru-news.csv.gz'\n",
        "data = list(load_lenta(path))\n",
        "data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DEk2PI3NU10",
        "outputId": "dd781b07-2f58-4db1-9232-93bef589797a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LentaRecord(\n",
              "    url='https://lenta.ru/news/2018/12/14/cancer/',\n",
              "    title='Названы регионы России с\\xa0самой высокой смертностью от\\xa0рака',\n",
              "    text='Вице-премьер по социальным вопросам Татьяна Голикова рассказала, в каких регионах России зафиксирована наиболее высокая смертность от рака, сообщает РИА Новости. По словам Голиковой, чаще всего онкологические заболевания становились причиной смерти в Псковской, Тверской, Тульской и Орловской областях, а также в Севастополе. Вице-премьер напомнила, что главные факторы смертности в России — рак и болезни системы кровообращения. В начале года стало известно, что смертность от онкологических заболеваний среди россиян снизилась впервые за три года. По данным Росстата, в 2017 году от рака умерли 289 тысяч человек. Это на 3,5 процента меньше, чем годом ранее.',\n",
              "    topic='Россия',\n",
              "    tags='Общество',\n",
              "    date=None\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxjCG9EriyBj",
        "outputId": "296c8488-b3a6-4d4f-bec4-fb58cf3da36c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "739351"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Возьмём только 10000 статей"
      ],
      "metadata": {
        "id": "M_pFyiDkuhrz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_sequence = 10000"
      ],
      "metadata": {
        "id": "OI62jQVUjZJB"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Возьмём только их оглавления"
      ],
      "metadata": {
        "id": "pcuFt3f4uo1o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_text = list(map(lambda x: x.title, data[:max_sequence]))\n",
        "data_text[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "PqDeT2_iTwhJ",
        "outputId": "42a37f12-e103-4160-c303-ae9e7bf0fa15"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Названы регионы России с\\xa0самой высокой смертностью от\\xa0рака'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Модель:"
      ],
      "metadata": {
        "id": "kSBo6RKwUuqt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Модель предсказывает комбинации из 18 чувствительных тем."
      ],
      "metadata": {
        "id": "wBGDStLtn7UV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"apanc/russian-sensitive-topics\")"
      ],
      "metadata": {
        "id": "K6XHGr8_VnOl"
      },
      "execution_count": 200,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification"
      ],
      "metadata": {
        "id": "J57PpbangK2M"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(\"apanc/russian-sensitive-topics\")"
      ],
      "metadata": {
        "id": "hb68jF6Ife9O"
      },
      "execution_count": 201,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Берём только ту часть, которая строит эмбеддинг слов в предложении"
      ],
      "metadata": {
        "id": "DU7IgXzmCXPh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.base_model.embeddings"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0qYwaboD2tV",
        "outputId": "75289707-e106-40c2-9616-48ede916f68d"
      },
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertEmbeddings(\n",
              "  (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
              "  (position_embeddings): Embedding(512, 768)\n",
              "  (token_type_embeddings): Embedding(2, 768)\n",
              "  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 186
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.base_model.embeddings.to('cuda:0')"
      ],
      "metadata": {
        "id": "fTU96HbfCTn6"
      },
      "execution_count": 202,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Возьмём только первые 100 символов оглавления"
      ],
      "metadata": {
        "id": "sf8huZb5umyR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_symbols = 100"
      ],
      "metadata": {
        "id": "bkD_FiKIjzj-"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_text[0][:100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "28ftCZvNjiav",
        "outputId": "557bc4c9-d13e-4700-c9c0-500f268f984a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Названы регионы России с\\xa0самой высокой смертностью от\\xa0рака'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(data_text, max_length=max_symbols, padding='max_length', truncation=True, return_tensors=\"pt\").to('cuda:0')"
      ],
      "metadata": {
        "id": "tE1kVHoZggg2"
      },
      "execution_count": 203,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "wbx3rnxWuCt6"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Формируем для каждого текста свой вектор"
      ],
      "metadata": {
        "id": "frSkFTcCvPT-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "xob1y_fsG8fA"
      },
      "execution_count": 197,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_vec = []\n",
        "batch_size = 64\n",
        "i = 0\n",
        "epochs = max_sequence // batch_size\n",
        "epochs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wgIVplVJuJO_",
        "outputId": "5e160dc9-d4e6-4b37-84b6-fc3aae9f3ec7"
      },
      "execution_count": 224,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "156"
            ]
          },
          "metadata": {},
          "execution_count": 224
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for _ in tqdm(range(epochs)):\n",
        "  data_vec.extend(torch.max(model(inputs['input_ids'][i:i+batch_size]), 1).values.cpu().detach().numpy())\n",
        "  i+=batch_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvaJxRu6tRCj",
        "outputId": "40c05b1e-6a84-4f60-df40-93179860aeb8"
      },
      "execution_count": 225,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 156/156 [00:00<00:00, 580.10it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_vec[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cO5xTbjyDDgA",
        "outputId": "d7a14429-8b19-41a5-fdce-34b14d104ce2"
      },
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(768,)"
            ]
          },
          "metadata": {},
          "execution_count": 209
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Поиск"
      ],
      "metadata": {
        "id": "UeScmd6Qvapt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import NearestNeighbors"
      ],
      "metadata": {
        "id": "4k4KK0DZvrOc"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def search(text, data, top_n=5):\n",
        "  inputs = tokenizer(text, max_length=max_symbols, padding='max_length', truncation=True, return_tensors=\"pt\").to('cuda:0')\n",
        "  text_vec = torch.max(model(inputs['input_ids']), 1).values.cpu().detach().numpy()[0]\n",
        "  neigh = NearestNeighbors(n_neighbors=top_n)\n",
        "  neigh.fit(data)\n",
        "  result = neigh.kneighbors([text_vec], return_distance=False)[0]\n",
        "  return result"
      ],
      "metadata": {
        "id": "zo-6jL2XvxXm"
      },
      "execution_count": 226,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "result = search('Премия лучший человек года', data_vec, top_n=3)\n",
        "j=1\n",
        "for i in result:\n",
        "  print(f'{j}.', data_text[i])\n",
        "  j+=1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gby4o18LLJSf",
        "outputId": "e5c162f4-f87a-4a8f-95dd-37b205a6fd14"
      },
      "execution_count": 233,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Михалков назвал лучший сериал года\n",
            "2. Назван лучший фильм года\n",
            "3. Определились спортсмены года в России\n",
            "CPU times: user 65.7 ms, sys: 38.1 ms, total: 104 ms\n",
            "Wall time: 89.2 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "result = search('Париж ответил Трампу', data_vec, top_n=5)\n",
        "j=1\n",
        "for i in result:\n",
        "  print(f'{j}.', data_text[i])\n",
        "  j+=1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3wCyb-my2rn",
        "outputId": "38e26bdc-71bb-4e2a-a63f-abca66ae8608"
      },
      "execution_count": 234,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Париж ответил Трампу\n",
            "2. Трампу нашли оппонента\n",
            "3. Трамп проигнорировал Путина\n",
            "4. Путин нашел замену Трампу\n",
            "5. Путин и Трамп пообщались\n",
            "CPU times: user 61.3 ms, sys: 44.1 ms, total: 105 ms\n",
            "Wall time: 148 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Так же можно получить полные данные по каждой найденной статье"
      ],
      "metadata": {
        "id": "jWCm8tDhL7rT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "j=0\n",
        "for i in result:\n",
        "  print(f'{j}.', data[i])\n",
        "  j+=1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GwD6RlZLMBiL",
        "outputId": "8bb7dfda-496d-43bc-b5b5-abf1016e57e0"
      },
      "execution_count": 237,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0. LentaRecord(url='https://lenta.ru/news/2018/12/09/not/', title='Париж ответил Трампу', text='Глава МИД Франции Жан-Ив Ле Дриан призвал президента США Дональда Трампа, отреагировавшего на протесты в Париже, не вмешиваться во внутренние дела республики. Об этом сообщает Daily Mail. «Мы не участвуем во внутренней американской политике и хотим, чтобы к нам относились взаимно. Я говорю это Дональду Трампу, и президент Франции [Эммануэль Макрон] говорит тоже: оставь нашу нацию», — сказал министр в ходе выступления по телевидению. Трамп, комментируя манифестации во французской столице, посоветовал властям республики отказаться от Парижского соглашения по климату и снизить налоги. Это уже второй за последние дни случай, когда американский лидер увязывает тему протестов во Франции с мнением об ошибочности Парижского соглашения. Протесты во Франции, сопровождающиеся беспорядками, стычками с полицией и массовыми арестами, продолжаются с октября. Акции были вызваны планами правительства повысить налоги на бензин, однако не прекратились и после того, как власти объявили о введении моратория на рост тарифов.', topic='Мир', tags='Политика', date=None)\n",
            "1. LentaRecord(url='https://lenta.ru/news/2018/10/11/bloomberg/', title='Трампу нашли оппонента', text='Бывший мэр американского города Нью-Йорка Майкл Блумберг заново вступил в ряды Демократической партии США. Это свидетельствует о том, что он намерен баллотироваться на пост президента страны в 2020 году, сообщает NBC News. «Сегодня я вновь вступаю в Демократическую партию, членом которой я был большую часть своей жизни, потому что нам нужны демократы, которые создадут контроль и устойчивость, так необходимые нашему народу», — написал он в своем Instagram. At key points in U.S. history, one of the two parties has served as a bulwark against those who threaten our Constitution. Two years ago at the Democratic Convention, I warned of those threats. Today, I have re-registered as a Democrat – I had been a member for most of my life – because we need Democrats to provide the checks and balance our nation so badly needs. Фото опубликовано @mikebloomberg Кори Левандовски, один из советников президента страны Дональда Трампа, заявил, что бывший градоначальник может составить серьезную конкуренцию действующему лидеру, если соберется выступить на президентских выборах от демократов. Его слова передало Reuters. Во время президентской гонки в 2016-м Блумберг поддержал кандидата от демократов Хиллари Клинтон. В сентябре The New York Times писала, что он всерьез задумывается над тем, чтобы выступить против Трампа на выборах 2020 года. Отмечалось, что одно из преимуществ Блумберга в том, что он не является «вашингтонским инсайдером». Кроме того, у него есть средства на проведение предвыборной кампании, а его политические взгляды поддерживают многие демократы. Блумберг был демократом до того, как впервые баллотировался на пост мэра Нью-Йорка в 2001 году. Тогда он был избран от Республиканской партии и должен был вступить в нее. От республиканцев он был переизбран и в 2005-м, а в двумя годами позже стал независимым кандидатом. Как независимый выдвиженец он был вновь избран на пост в 2009 году. Бывший мэр создал состояние, став основателем медиакорпорации Bloomberg LP. Как отмечает NBC, ранее он пообещал помочь демократам в Белом доме 80 миллионами долларов.', topic='Мир', tags='Политика', date=None)\n",
            "2. LentaRecord(url='https://lenta.ru/news/2018/11/30/putin_tramp/', title='Трамп проигнорировал Путина', text='Президент России Владимир Путин и его американский коллега Дональд Трамп не поприветствовали друг друга во время общего фотографирования на саммите «Большой двадцатки» в Буэнос-Айресе. Об этом сообщает «Интерфакс». Как отмечает агентство, Путин поднялся на подиум для фотографирования раньше Трампа, но последний прошел на свое место, не обратив внимания на российского лидера. После этого главы государств направились в зал, где проходило первое пленарное заседание. Как сообщили журналисты, Путин шел впереди Трампа, и они не пересеклись. Отмечается, что хозяин Белого дома прибыл на первое заседание мероприятия с опозданием. В зале пленарного заседания Путин поздоровался с наследным принцем Саудовской Аравии Мухаммедом бин Салманом аль-Саудом, в то время как Трамп общался с другими участниками мероприятия.  На «пленарке» Трамп и Путин будут сидеть далеко друг от друга: места между ними отведены наследному принцу Саудовской Аравии, президенту Южноафриканской Республики Сирилу Рамафосе, турецкому лидеру Реджепу Тайипу Эрдогану и премьер-министру Великобритании Терезе Мэй. Ранее 30 ноября  сообщалось, что российский и американский лидеры после отмены переговоров не будут проводить встречу «на ногах». Днем ранее Трамп отменил встречу с Путиным, сославшись на инцидент в Керченском проливе. В Москве такой шаг объяснили внутриполитическими причинами. Ожидалось, что лидеры двух стран встретятся в ходе саммита G20, который пройдет в Буэнос-Айресе с 30 ноября по 1 декабря. 25 ноября пограничная служба ФСБ России задержала три украинских военных корабля, которые без предупреждения нарушили морскую границу и совершали опасные маневры в российских водах. 24 моряка были взяты под стражу. В ответ на это Киев ввел военное положение в некоторых областях Украины. Сенат США единогласно обвинил Москву в агрессии.', topic='Мир', tags='Политика', date=None)\n",
            "3. LentaRecord(url='https://lenta.ru/news/2018/12/01/friendship_ended_with_mudasir/', title='Путин нашел замену Трампу', text='Президент России Владимир Путин 1 декабря проведет встречу с турецким лидером Реджепом Тайипом Эрдоганом, время на это нашлось благодаря отмене встречи с президентом США Дональдом Трампом. Об этом со ссылкой на пресс-секретаря президента Дмитрия Пескова сообщает «Интерфакс». «Да, действительно завтра будет эта встреча в первой половине дня. Там возникла потребность продолжить доверительный диалог с Эрдоганом, в том числе этого требуют сирийские дела», — заявил Песков, отвечая на вопрос журналистов. Он подтвердил, что такая возможность появилась, в частности, благодаря отмене встречи с Трампом. «В том числе, хотя и не совсем в это время. График чуть-чуть модифицировали, и теперь согласована дополнительная встреча», — сказал он. 29 ноября Трамп отменил  встречу с Путиным, которая должна была пройти на саммите G20 в Аргентине. Причиной отмены стал инцидент в Керченском проливе, в результате которого Россия арестовала три корабля ВМС Украины. Однако, по словам официального представителя МИД России Марии Захаровой, Трамп принял такое решение скорее по внутриполитическим причинам. 28 ноября пресс-служба Кремля сообщила, что Путин и Эрдоган провели телефонный разговор, в котором «обменялись мнениями по вопросам стабильности и безопасности в Черноморском регионе», а также обсудили сотрудничество в Сирии.', topic='Мир', tags='Политика', date=None)\n",
            "4. LentaRecord(url='https://lenta.ru/news/2018/12/01/pu/', title='Путин и\\xa0Трамп пообщались', text='Президент России Владимир Путин и его американский коллега Дональд Трамп смогли пообщаться на саммите «Большой двадцатки» в Буэнос-Айресе. Об этом заявил пресс-секретарь российского лидера Дмитрий Песков, передает в субботу, 1 декабря, «Интерфакс». «Короткий контакт был», — сказал Песков журналистам в кулуарах саммита. 1 декабря сообщалось, что Путин встретится с турецким лидером Реджепом Тайипом Эрдоганом, время на это нашлось благодаря отмене встречи с президентом Трампом. 30 ноября помощник Путина Юрий Ушаков заявил о том, что президент России и лидер США все-таки поприветствовали друг друга на саммите «Большой двадцатки». При этом он не уточнил, было ли это рукопожатие, и в какой момент главы государств обменялись приветствием. Ранее стало известно о том, что Трамп не поприветствовал своего российского коллегу во время общего фотографирования.', topic='Мир', tags='Политика', date=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Вывод:\n",
        "\n",
        "Поисковая модель справилась хорошо. Видно, что она показывает похожие по тематике запроса статьи.\n",
        "\n",
        "Стоит отметить, что агрегация эмбедингов слов в предложении с помощью max показала себя лучше mean."
      ],
      "metadata": {
        "id": "vWH6iSBEKL80"
      }
    }
  ]
}